{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiEval Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a basic parameter sweep with LensKits `MultiEval` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We first need to import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.batch import MultiEval\n",
    "from lenskit.crossfold import partition_users, SampleN\n",
    "from lenskit.algorithms import basic, als, item_knn, user_knn\n",
    "from lenskit.datasets import MovieLens\n",
    "from lenskit import topn, util\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress bars are useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a little while to run things, and can get kinda quiet in here. Let's set up logging so we can see the logging output in the notebook's message stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.log log already initialized\n",
      "[   INFO] lenskit.util.log log already initialized\n",
      "[   INFO] lenskit.util.log log already initialized\n",
      "[   INFO] lenskit.util.log notebook logging configured\n",
      "[   INFO] lenskit.util.log notebook logging configured\n",
      "[   INFO] lenskit.util.log notebook logging configured\n",
      "[   INFO] lenskit.util.log notebook logging configured\n"
     ]
    }
   ],
   "source": [
    "util.log_to_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up the data access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('../data/ml-latest-small')\n",
    "#mlsmall = MovieLens('../data/ml-1m')\n",
    "#mlsmall = MovieLens('../data/ml-20m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to run our evaluation and store its output in the `my-eval` directory, generating 20-item recommendation lists::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = MultiEval('my-eval', recommend = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a 5-fold cross-validation setup.  We save the data into a list in memory so we have access to the test data later.  In a larger experiment, you might write the partitions to disk and pass the file names to `add_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n"
     ]
    }
   ],
   "source": [
    "pairs = list(partition_users(mlsmall.ratings, 5, SampleN(5)))\n",
    "eval.add_datasets(pairs, name = 'ML-Small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([item_knn.ItemItem(nnbrs = f) for f in [10, 20, 30, 50, 75, 100]], \n",
    "                    attrs = ['nnbrs'], name = 'ItemKNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([user_knn.UserUser(nnbrs = f) for f in [10, 20, 30, 50, 75, 100]], \n",
    "                    attrs = ['nnbrs'], name = 'UserKNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add a popular baseline for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms(basic.Popular(), name = 'Pop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we will run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774b857f160d46269920c4354f022fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=65.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi starting run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 31ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 33ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 34ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 36ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 57ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 60ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 63ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 66ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 83ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 86ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 88ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 90ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 92ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 93ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 95ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 96ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 103ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 105ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 106ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 107ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.46s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.47s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.47s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.47s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.96s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.97s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.98s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.66s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.66s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  241ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  243ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  245ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  247ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.13s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.13s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.14s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.14s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.88s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.88s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.88s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.88s\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=10, msize=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.44s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.44s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.44s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.44s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.20s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.20s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.20s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.20s\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 1: ItemItem(nnbrs=10, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=20, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=20, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=20, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=20, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=20, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=20, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=20, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=20, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 25ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 27ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 28ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 30ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 49ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 51ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 52ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 54ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 67ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 69ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 70ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 72ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 74ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 76ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 82ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 84ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 94ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 96ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 97ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 98ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.25s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.36s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.37s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.37s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.37s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.84s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.85s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.85s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.85s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.87s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.87s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.75s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.75s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.75s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.75s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=20, msize=None) in 3.82s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=20, msize=None) in 3.82s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=20, msize=None) in 3.82s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=20, msize=None) in 3.82s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=20, msize=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  250ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  252ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  255ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  260ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.00s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.74s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.74s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.74s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.74s\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=20, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=20, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=20, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=20, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=20, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=20, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.93s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.93s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.93s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.94s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.65s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.65s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.65s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.65s\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 2: ItemItem(nnbrs=20, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=30, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=30, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=30, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=30, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=30, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=30, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=30, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=30, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 26ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 28ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 34ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 37ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 53ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 56ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 60ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 62ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 74ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 76ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 78ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 82ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 86ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 87ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 89ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 90ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 102ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 104ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 105ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 106ms] splitting 9056 items (94742 ratings) into 10 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.24s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.34s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.79s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.80s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.45s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.45s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.45s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.45s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=30, msize=None) in 3.50s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=30, msize=None) in 3.50s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=30, msize=None) in 3.50s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=30, msize=None) in 3.50s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  206ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  208ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  209ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  210ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.19s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.19s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.19s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.19s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.92s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.92s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.92s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.92s\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=30, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=30, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=30, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=30, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=30, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=30, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.83s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.83s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.83s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.84s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.62s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.62s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.62s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.62s\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 3: ItemItem(nnbrs=30, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi starting run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=50, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=50, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=50, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=50, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=50, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=50, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=50, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=50, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 22ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 25ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 27ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 28ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 45ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 48ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 50ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 53ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 65ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 67ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 68ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 69ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 71ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 72ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 74ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 75ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 88ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 91ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 93ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 94ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.23s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.23s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.23s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.23s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.35s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.35s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.35s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.35s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.82s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.82s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.82s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.82s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.82s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.83s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.83s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.83s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.54s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.54s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.54s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.54s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=50, msize=None) in 3.60s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=50, msize=None) in 3.60s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=50, msize=None) in 3.60s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=50, msize=None) in 3.60s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  185ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  186ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  188ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  189ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.29s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.29s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.29s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.29s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.99s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.99s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.99s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.99s\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=50, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=50, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=50, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=50, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=50, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=50, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.15s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.15s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.16s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.16s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.88s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.88s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.88s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.88s\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 4: ItemItem(nnbrs=50, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=75, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=75, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=75, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=75, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=75, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=75, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=75, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=75, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 21ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 22ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 24ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 25ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 48ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 50ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 51ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 52ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 65ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 72ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 73ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 75ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 78ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 80ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 82ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 89ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 104ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 106ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 108ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 111ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.29s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.29s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.29s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.30s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.88s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.88s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.88s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.88s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.88s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.89s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.89s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.89s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.62s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.62s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.62s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.63s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=75, msize=None) in 3.68s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=75, msize=None) in 3.68s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=75, msize=None) in 3.68s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=75, msize=None) in 3.68s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=75, msize=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  210ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  210ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  212ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  213ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.39s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.39s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.39s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.39s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.17s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.17s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.17s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.17s\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=75, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=75, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=75, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=75, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=75, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=75, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.34s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.35s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.35s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.35s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 11.15s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 11.15s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 11.15s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 11.15s\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 5: ItemItem(nnbrs=75, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=100, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=100, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=100, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=100, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=100, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=100, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=100, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=100, msize=None) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 23ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 26ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 27ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 29ms] made sparse matrix for 9056 items (99329 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 44ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 47ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 51ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 54ms] computed means for 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 64ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 67ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 68ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 69ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 75ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 78ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 81ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 83ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 92ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 94ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 95ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 97ms] splitting 9056 items (94742 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.30s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.31s] computed 8766276 similarities for 9056 items in 10 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.algorithms.item_knn [2.31s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.31s] computed 8766276 similarities for 9056 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.43s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.43s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.43s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.43s] sorting similarity matrix with 8766276 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.92s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.92s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.92s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.92s] got neighborhoods for 5734 of 9056 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.92s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.93s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.93s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.93s] computed 8766276 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.65s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=100, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=100, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=100, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=100, msize=None) in 3.70s\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  206ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  208ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  210ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  212ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.85s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.85s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.85s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.85s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.53s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.53s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.53s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.53s\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/ItemItem(nnbrs=100, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=100, msize=None) to 1341 pickle bytes with 17 buffers of 212430704 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=100, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=100, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=100, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=100, msize=None) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.66s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.67s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.67s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.67s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.47s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.47s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.47s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.47s\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 6: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 6: ItemItem(nnbrs=100, msize=None) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=10, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=10, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=10, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=10, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=10, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=10, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=10, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=10, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=10, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=10, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=10, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=10, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  27ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  28ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  32ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  33ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.04s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.04s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.05s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.05s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 10.56s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 10.56s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 10.56s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 10.56s\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=10, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.43s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.44s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.44s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 10.44s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.96s\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 7: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 7: UserUser(nnbrs=10, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=20, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=20, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=20, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=20, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=20, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=20, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=20, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=20, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=20, min_sim=0) in  94ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=20, min_sim=0) in  94ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=20, min_sim=0) in  94ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=20, min_sim=0) in  94ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  27ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  29ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  31ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  33ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.50s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.51s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.51s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 10.51s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 11.07s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 11.07s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 11.07s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 11.07s\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=20, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=20, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=20, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=20, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=20, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=20, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 12.95s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 12.95s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 12.95s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 12.95s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 13.46s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 13.46s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 13.46s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 13.46s\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 8: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 8: UserUser(nnbrs=20, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=30, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=30, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=30, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=30, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=30, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=30, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=30, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=30, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=30, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=30, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=30, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=30, min_sim=0) in  86ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=30, min_sim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  26ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  28ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  32ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  34ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.60s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.60s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.60s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.60s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.09s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.09s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.09s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.09s\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=30, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=30, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=30, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=30, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=30, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=30, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.46s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.46s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.46s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 11.47s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.27s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.27s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.27s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 12.27s\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 9: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 9: UserUser(nnbrs=30, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=50, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=50, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=50, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=50, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=50, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=50, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=50, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=50, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=50, min_sim=0) in  89ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=50, min_sim=0) in  89ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=50, min_sim=0) in  89ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=50, min_sim=0) in  89ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  19ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  20ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  21ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  22ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 12.46s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 12.46s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 12.46s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 12.46s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 12.94s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 12.94s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 12.94s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 12.94s\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=50, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=50, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=50, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=50, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=50, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=50, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.53s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.53s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.54s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.54s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.11s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.11s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.11s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.11s\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 10: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 10: UserUser(nnbrs=50, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=75, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=75, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=75, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=75, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=75, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=75, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=75, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=75, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=75, min_sim=0) in  84ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=75, min_sim=0) in  84ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=75, min_sim=0) in  84ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=75, min_sim=0) in  84ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  25ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  28ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  30ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  33ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.72s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.72s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.72s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.72s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.22s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.22s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.22s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.22s\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\predictions.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=75, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=75, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=75, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=75, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=75, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=75, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.59s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.06s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.06s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.06s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 10.06s\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 11: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 11: UserUser(nnbrs=75, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=100, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=100, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=100, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting UserUser(nnbrs=100, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=100, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=100, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=100, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm UserUser(nnbrs=100, min_sim=0) on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=100, min_sim=0) in  102ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=100, min_sim=0) in  102ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=100, min_sim=0) in  102ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm UserUser(nnbrs=100, min_sim=0) in  102ms\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating 675 predictions for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  23ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  25ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  26ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  28ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.66s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.66s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.66s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.66s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.16s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.16s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.16s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 9.16s\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for TopN/UserUser(nnbrs=100, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=100, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=100, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=100, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=100, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=100, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.42s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.42s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.42s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.42s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 9.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 9.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 9.96s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 9.96s\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 12: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 12: UserUser(nnbrs=100, min_sim=0) on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi training algorithm Popular on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm Popular on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm Popular on 99329 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm Popular on 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm Popular in  55ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm Popular in  55ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm Popular in  55ms\n",
      "[   INFO] lenskit.batch._multi trained algorithm Popular in  55ms\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for Popular\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for Popular\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for Popular\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 135 users for Popular\n",
      "[   INFO] lenskit.sharing.shm serialized Popular to 967 pickle bytes with 7 buffers of 695164 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized Popular to 967 pickle bytes with 7 buffers of 695164 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized Popular to 967 pickle bytes with 7 buffers of 695164 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized Popular to 967 pickle bytes with 7 buffers of 695164 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with Popular for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with Popular for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with Popular for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with Popular for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 4.06s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 4.06s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 4.06s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 4.06s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 4.38s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 4.38s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 4.38s\n",
      "[   INFO] lenskit.batch._multi generated recommendations in 4.38s\n",
      "[   INFO] lenskit.batch._multi run 13: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 13: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 13: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi run 13: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch._multi finished run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi finished run 13: Popular on ML-Small:1\n",
      "[   INFO] lenskit.batch._multi starting run 14: ItemItem(nnbrs=10, msize=None) on ML-Small:2\n",
      "[   INFO] lenskit.batch._multi starting run 14: ItemItem(nnbrs=10, msize=None) on ML-Small:2\n",
      "[   INFO] lenskit.batch._multi starting run 14: ItemItem(nnbrs=10, msize=None) on ML-Small:2\n",
      "[   INFO] lenskit.batch._multi starting run 14: ItemItem(nnbrs=10, msize=None) on ML-Small:2\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi adapting ItemItem(nnbrs=10, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99334 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99334 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99334 ratings\n",
      "[   INFO] lenskit.batch._multi training algorithm ItemItem(nnbrs=10, msize=None) on 99334 ratings\n",
      "[   INFO] lenskit.algorithms.item_knn [ 22ms] made sparse matrix for 9058 items (99334 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 24ms] made sparse matrix for 9058 items (99334 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 26ms] made sparse matrix for 9058 items (99334 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 30ms] made sparse matrix for 9058 items (99334 ratings from 671 users)\n",
      "[   INFO] lenskit.algorithms.item_knn [ 49ms] computed means for 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 51ms] computed means for 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 52ms] computed means for 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 53ms] computed means for 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [ 63ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 65ms] normalized rating matrix columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.algorithms.item_knn [ 67ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 70ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms.item_knn [ 72ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 74ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 78ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 80ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms.item_knn [ 87ms] splitting 9058 items (94654 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 89ms] splitting 9058 items (94654 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 90ms] splitting 9058 items (94654 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [ 92ms] splitting 9058 items (94654 ratings) into 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.30s] computed 8767890 similarities for 9058 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.30s] computed 8767890 similarities for 9058 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.31s] computed 8767890 similarities for 9058 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.31s] computed 8767890 similarities for 9058 items in 10 blocks\n",
      "[   INFO] lenskit.algorithms.item_knn [2.40s] sorting similarity matrix with 8767890 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8767890 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8767890 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.41s] sorting similarity matrix with 8767890 entries\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] got neighborhoods for 5731 of 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] got neighborhoods for 5731 of 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] got neighborhoods for 5731 of 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] got neighborhoods for 5731 of 9058 items\n",
      "[   INFO] lenskit.algorithms.item_knn [2.86s] computed 8767890 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.87s] computed 8767890 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.87s] computed 8767890 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [2.87s] computed 8767890 neighbor pairs\n",
      "[   INFO] lenskit.algorithms.item_knn [3.56s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.56s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.56s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.item_knn [3.56s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.61s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.61s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.61s\n",
      "[   INFO] lenskit.batch._multi trained algorithm ItemItem(nnbrs=10, msize=None) in 3.61s\n",
      "[   INFO] lenskit.batch._multi generating 670 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 670 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 670 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating 670 predictions for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  195ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  195ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  198ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  199ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 7.99s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.00s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.69s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.69s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.69s\n",
      "[   INFO] lenskit.batch._multi generated predictions in 8.69s\n",
      "[   INFO] lenskit.batch._multi run 14: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 14: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 14: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi run 14: writing results to my-eval\\predictions.parquet\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 134 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 134 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 134 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.batch._multi generating recommendations for 134 users for TopN/ItemItem(nnbrs=10, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItem(nnbrs=10, msize=None) to 1341 pickle bytes with 17 buffers of 212469616 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/ItemItem(nnbrs=10, msize=None) for 134 users (n_jobs=None)\n"
     ]
    }
   ],
   "source": [
    "eval.run(progress = tqdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that the experiment is run, we can read its outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Partition</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>AlgoStr</th>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "      <th>TrainTime</th>\n",
       "      <th>PredTime</th>\n",
       "      <th>RecTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>ItemItem(nnbrs=10, msize=None)</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.659061</td>\n",
       "      <td>9.134039</td>\n",
       "      <td>10.360558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>ItemItem(nnbrs=20, msize=None)</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.356655</td>\n",
       "      <td>17.644546</td>\n",
       "      <td>14.598085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>ItemItem(nnbrs=30, msize=None)</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.658997</td>\n",
       "      <td>9.073628</td>\n",
       "      <td>10.698250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>ItemItem(nnbrs=50, msize=None)</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.860284</td>\n",
       "      <td>8.947400</td>\n",
       "      <td>11.129404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML-Small</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>ItemItem(nnbrs=75, msize=None)</td>\n",
       "      <td>ItemKNN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.667355</td>\n",
       "      <td>10.018123</td>\n",
       "      <td>11.644256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DataSet  Partition AlgoClass                         AlgoStr     name  \\\n",
       "RunId                                                                           \n",
       "1      ML-Small          1  ItemItem  ItemItem(nnbrs=10, msize=None)  ItemKNN   \n",
       "2      ML-Small          1  ItemItem  ItemItem(nnbrs=20, msize=None)  ItemKNN   \n",
       "3      ML-Small          1  ItemItem  ItemItem(nnbrs=30, msize=None)  ItemKNN   \n",
       "4      ML-Small          1  ItemItem  ItemItem(nnbrs=50, msize=None)  ItemKNN   \n",
       "5      ML-Small          1  ItemItem  ItemItem(nnbrs=75, msize=None)  ItemKNN   \n",
       "\n",
       "       nnbrs  TrainTime   PredTime    RecTime  \n",
       "RunId                                          \n",
       "1       10.0   3.659061   9.134039  10.360558  \n",
       "2       20.0   7.356655  17.644546  14.598085  \n",
       "3       30.0   3.658997   9.073628  10.698250  \n",
       "4       50.0   3.860284   8.947400  11.129404  \n",
       "5       75.0   3.667355  10.018123  11.644256  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace = True)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes each run - a data set, partition, and algorithm combination.  To evaluate, we need to get the actual recommendations, and combine them with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1903</td>\n",
       "      <td>5.302788</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107083</td>\n",
       "      <td>5.200252</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>893</td>\n",
       "      <td>5.019846</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6273</td>\n",
       "      <td>4.914663</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95858</td>\n",
       "      <td>4.887177</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item     score  user  rank  RunId\n",
       "0    1903  5.302788    20     1      1\n",
       "1  107083  5.200252    20     2      1\n",
       "2     893  5.019846    20     3      1\n",
       "3    6273  4.914663    20     4      1\n",
       "4   95858  4.887177    20     5      1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compute per-(run,user) evaluations of the recommendations *before* combining with metadata. \n",
    "\n",
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.topn analyzing 1113500 recommendations (3355 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 1113500 recommendations (3355 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 1113500 recommendations (3355 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 1113500 recommendations (3355 truth rows)\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x0000016732207AC0> to 230491 pickle bytes with 2016 buffers of 35699100 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x0000016732207AC0> to 230491 pickle bytes with 2016 buffers of 35699100 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x0000016732207AC0> to 230491 pickle bytes with 2016 buffers of 35699100 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x0000016732207AC0> to 230491 pickle bytes with 2016 buffers of 35699100 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.topn measured 20783 lists in 30.79s\n",
      "[   INFO] lenskit.topn measured 20783 lists in 30.79s\n",
      "[   INFO] lenskit.topn measured 20783 lists in 30.79s\n",
      "[   INFO] lenskit.topn measured 20783 lists in 30.80s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  precision\n",
       "RunId user                  \n",
       "1     20    100.0        0.0\n",
       "      32    100.0        0.0\n",
       "      34    100.0        0.0\n",
       "      35    100.0        0.0\n",
       "      36    100.0        0.0"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.precision) # precision, recall, recip_rank, dcg, ndcg\n",
    "raw_ndcg = rla.compute(recs, truth)\n",
    "raw_ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>precision</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>nnbrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>20</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemItem</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  precision AlgoClass  nnbrs\n",
       "RunId user                                   \n",
       "1     20    100.0        0.0  ItemItem   10.0\n",
       "      32    100.0        0.0  ItemItem   10.0\n",
       "      34    100.0        0.0  ItemItem   10.0\n",
       "      35    100.0        0.0  ItemItem   10.0\n",
       "      36    100.0        0.0  ItemItem   10.0"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "ndcg = raw_ndcg.join(runs[['AlgoClass', 'nnbrs']], on = 'RunId')\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the overall average performance for each algorithm configuration - fillna makes the group-by happy with Popular's lack of a feature count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlgoClass  nnbrs\n",
       "0          0.0      0.002156\n",
       "ItemItem   10.0     0.000715\n",
       "           20.0     0.000417\n",
       "           30.0     0.000402\n",
       "           50.0     0.000343\n",
       "           75.0     0.000283\n",
       "           100.0    0.000268\n",
       "Popular    0.0      0.014978\n",
       "UserUser   10.0     0.000015\n",
       "           20.0     0.000015\n",
       "           30.0     0.000015\n",
       "           50.0     0.000015\n",
       "           75.0     0.000015\n",
       "           100.0    0.000015\n",
       "Name: precision, dtype: float64"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "ndcg.fillna(0).groupby(['AlgoClass', 'nnbrs'])['precision'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'nDCG')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "mf_scores = ndcg.groupby(['AlgoClass', 'nnbrs'])['ndcg'].mean().reset_index()\n",
    "#pop_score = ndcg[ndcg['AlgoClass'] == 'Popular']['ndcg'].mean()\n",
    "#plt.axhline(pop_score, color='grey', linestyle='--', label='Popular')\n",
    "for algo, data in mf_scores.groupby('AlgoClass'):\n",
    "    plt.plot(data['nnbrs'], data['ndcg'], label=algo)\n",
    "plt.legend()\n",
    "plt.xlabel('nnbrs')\n",
    "plt.ylabel('nDCG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
