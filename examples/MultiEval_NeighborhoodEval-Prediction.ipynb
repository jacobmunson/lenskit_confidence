{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiEval Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates a basic parameter sweep with LensKits `MultiEval` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We first need to import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence',\n",
       " 'C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence',\n",
       " 'C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence\\\\examples',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\python38.zip',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\binpickle-0.3.2-py3.8.egg',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\pyarrow-2.0.0-py3.8-win-amd64.egg',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\Jacob\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\Jacob\\\\.ipython']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "\n",
    "#import os\n",
    "#os.getcwd()\n",
    "#os.chdir('C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence\\\\lenskit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,'C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set PYTHONPATH=C:\\\\Users\\\\Jacob\\\\Documents\\\\GitHub\\\\lenskit_confidence\\\\lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.batch import MultiEval\n",
    "from lenskit.crossfold import partition_users, SampleN\n",
    "from lenskit.algorithms import basic, als, item_knn, user_knn\n",
    "from lenskit.datasets import MovieLens\n",
    "from lenskit import topn, util, metrics\n",
    "from lenskit.metrics import predict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.log log already initialized\n",
      "[   INFO] lenskit.util.log log already initialized\n",
      "[   INFO] lenskit.util.log notebook logging configured\n",
      "[   INFO] lenskit.util.log notebook logging configured\n",
      "[   INFO] lenskit.util.log notebook logging configured\n"
     ]
    }
   ],
   "source": [
    "util.log_to_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  item  rating   timestamp\n",
      "0     1    31     2.5  1260759144\n",
      "1     1  1029     3.0  1260759179\n",
      "2     1  1061     3.0  1260759182\n",
      "3     1  1129     2.0  1260759185\n",
      "4     1  1172     4.0  1260759205\n",
      "100004\n",
      "[   INFO] lenskit.algorithms.bias building bias model for 100004 ratings\n",
      "[   INFO] lenskit.algorithms.bias building bias model for 100004 ratings\n",
      "[   INFO] lenskit.algorithms.bias global mean: 3.544\n",
      "[   INFO] lenskit.algorithms.bias global mean: 3.544\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.algorithms.bias computed means for 9066 items\n",
      "[   INFO] lenskit.algorithms.bias computed means for 9066 items\n",
      "[   INFO] lenskit.algorithms.bias computed means for 671 users\n",
      "[   INFO] lenskit.algorithms.bias computed means for 671 users\n",
      "[   INFO] lenskit.sharing.shm serialized Bias(ud=0.0, id=0.0) to 954 pickle bytes with 6 buffers of 233688 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized Bias(ud=0.0, id=0.0) to 954 pickle bytes with 6 buffers of 233688 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 100004 predictions for 671 users (setup took  13ms)\n",
      "[   INFO] lenskit.batch._predict generating 100004 predictions for 671 users (setup took  16ms)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch._predict generated 100004 predictions for 671 users in 8.69s\n",
      "[   INFO] lenskit.batch._predict generated 100004 predictions for 671 users in 8.69s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759144</td>\n",
       "      <td>2.166043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1029</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759179</td>\n",
       "      <td>2.689852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1260759182</td>\n",
       "      <td>2.532926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759185</td>\n",
       "      <td>2.299971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759205</td>\n",
       "      <td>3.248341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>671</td>\n",
       "      <td>6268</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1065579370</td>\n",
       "      <td>3.075544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>671</td>\n",
       "      <td>6269</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1065149201</td>\n",
       "      <td>4.218401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>671</td>\n",
       "      <td>6365</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1070940363</td>\n",
       "      <td>3.343837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>671</td>\n",
       "      <td>6385</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1070979663</td>\n",
       "      <td>3.780090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>671</td>\n",
       "      <td>6565</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1074784724</td>\n",
       "      <td>3.895544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100004 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating   timestamp  prediction\n",
       "0          1    31     2.5  1260759144    2.166043\n",
       "1          1  1029     3.0  1260759179    2.689852\n",
       "2          1  1061     3.0  1260759182    2.532926\n",
       "3          1  1129     2.0  1260759185    2.299971\n",
       "4          1  1172     4.0  1260759205    3.248341\n",
       "...      ...   ...     ...         ...         ...\n",
       "99999    671  6268     2.5  1065579370    3.075544\n",
       "100000   671  6269     4.0  1065149201    4.218401\n",
       "100001   671  6365     4.0  1070940363    3.343837\n",
       "100002   671  6385     2.5  1070979663    3.780090\n",
       "100003   671  6565     3.5  1074784724    3.895544\n",
       "\n",
       "[100004 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# move elsewhere\n",
    "from lenskit.algorithms.bias import Bias\n",
    "from lenskit.metrics.predict import rmse\n",
    "from lenskit import datasets\n",
    "ratings = datasets.MovieLens('../data/ml-latest-small').ratings\n",
    "bias = Bias()\n",
    "print(ratings.head())\n",
    "print(len(ratings))\n",
    "\n",
    "bias.fit(ratings)\n",
    "\n",
    "batch.predict(bias, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lenskit import batch, topn, datasets\n",
    "from lenskit.metrics.predict import rmse\n",
    "from lenskit.crossfold import partition_users, SampleN, partition_rows\n",
    "from lenskit.algorithms import als, Recommender\n",
    "from lenskit.algorithms import basic, als, item_knn, user_knn\n",
    "# Load MovieLens data in expected format\n",
    "ml = datasets.MovieLens('../data/ml-latest-small').ratings\n",
    "#print(ml.head())\n",
    "\n",
    "all_recs = []\n",
    "all_preds = []\n",
    "all_test = []\n",
    "\n",
    "samp = SampleN(5)\n",
    "#print(samp)\n",
    "#pairs = list(partition_users(ml.ratings, 5, SampleN(5)))\n",
    "nbhd_sizes = [5]\n",
    "\n",
    "for f in nbhd_sizes:\n",
    "    print('Starting neighborhood size: ', f)\n",
    "    for train, test in partition_rows(ml, 2): #partition_users(ml, 5, samp):\n",
    "        print(len(train))\n",
    "        print(len(test))\n",
    "        all_test.append(test)\n",
    "        print('Configuring algorithm...')\n",
    "        # configure the algorithm\n",
    "        algo = user_knn.UserUser(nnbrs = f) #als.BiasedMF(50)\n",
    "        # make sure it can recommend, not just predict\n",
    "        algo = Recommender.adapt(algo)\n",
    "        # train the algorithm\n",
    "        algo.fit(train)\n",
    "        print('Starting prediction process...')\n",
    "        # predict ratings\n",
    "        preds = batch.predict(algo, test)\n",
    "        preds['nnbhrs'] = f\n",
    "        all_preds.append(preds)\n",
    "        print('Starting recommendation process...')\n",
    "        # produce recommendations\n",
    "        users = test['user'].unique()\n",
    "        recs = batch.recommend(algo, users, 20)\n",
    "        all_recs.append(recs)\n",
    "        print('Finishing neighborhood size: ', f)\n",
    "\n",
    "# integrate test data; since splits are disjoint users\n",
    "# for a single data set, this is sufficient\n",
    "recs = pd.concat(all_recs, ignore_index=True)\n",
    "preds = pd.concat(all_preds, ignore_index=True)\n",
    "test = pd.concat(all_test, ignore_index=True)\n",
    "# compute RMSE\n",
    "print('RMSE:', rmse(preds['prediction'],preds['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = datasets.MovieLens('../data/ml-latest-small').ratings\n",
    "#ml = datasets.MovieLens('../data/ml-1m').ratings\n",
    "#mlsmall = MovieLens('../data/ml-10m')\n",
    "#mlsmall = MovieLens('../data/ml-20m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold partitioning 100004 rows for 671 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n",
      "Starting neighborhood size:  10\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  15ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  16ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  17ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 9.13s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 9.13s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 9.13s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.57s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.58s\n",
      "Finishing neighborhood size:  10\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  38ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  40ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  43ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.30s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.30s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.30s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.92s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.92s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.92s\n",
      "Finishing neighborhood size:  10\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  15ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  16ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  17ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.80s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.80s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.80s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.76s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.76s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.76s\n",
      "Finishing neighborhood size:  10\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  23ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  25ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  27ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.46s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.46s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.46s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.54s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.54s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.54s\n",
      "Finishing neighborhood size:  10\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  15ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  17ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  20ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.95s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.96s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.96s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=10, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=10, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.68s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.69s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.69s\n",
      "Finishing neighborhood size:  10\n",
      "Starting neighborhood size:  15\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99329 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  17ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  19ms)\n",
      "[   INFO] lenskit.batch._predict generating 675 predictions for 135 users (setup took  21ms)\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.81s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.81s\n",
      "[   INFO] lenskit.batch._predict generated 675 predictions for 135 users in 8.81s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983816 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 135 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.85s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.85s\n",
      "[   INFO] lenskit.batch._recommend recommended for 135 users in 9.85s\n",
      "Finishing neighborhood size:  15\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  16ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  19ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  20ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.06s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.06s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.06s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983936 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.59s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.59s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.59s\n",
      "Finishing neighborhood size:  15\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  22ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  25ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  26ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.93s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.93s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.94s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983896 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.58s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.58s\n",
      "Finishing neighborhood size:  15\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  16ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  17ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  18ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.17s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.17s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 9.17s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983976 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.60s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.61s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.61s\n",
      "Finishing neighborhood size:  15\n",
      "Configuring algorithm...\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "[   INFO] lenskit.algorithms.basic trained unrated candidate selector for 99334 ratings\n",
      "Starting prediction process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  18ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  20ms)\n",
      "[   INFO] lenskit.batch._predict generating 670 predictions for 134 users (setup took  23ms)\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.96s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.96s\n",
      "[   INFO] lenskit.batch._predict generated 670 predictions for 134 users in 8.96s\n",
      "Starting recommendation process...\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUser(nnbrs=15, min_sim=0) to 1121 pickle bytes with 13 buffers of 2983876 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommending with TopN/UserUser(nnbrs=15, min_sim=0) for 134 users (n_jobs=None)\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.69s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.70s\n",
      "[   INFO] lenskit.batch._recommend recommended for 134 users in 9.70s\n",
      "Finishing neighborhood size:  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from lenskit import batch, topn, datasets\n",
    "from lenskit.metrics.predict import rmse\n",
    "from lenskit.crossfold import partition_users, SampleN, partition_rows\n",
    "from lenskit.algorithms import als, Recommender\n",
    "from lenskit.algorithms import basic, als, item_knn, user_knn\n",
    "# Load MovieLens data in expected format\n",
    "\n",
    "#print(ml.head())\n",
    "\n",
    "all_recs = []\n",
    "all_preds = []\n",
    "all_test = []\n",
    "\n",
    "samp = SampleN(5)\n",
    "#print(samp)\n",
    "num_cv = 5\n",
    "pairs = list(partition_users(ml, num_cv, SampleN(5)))\n",
    "nbhd_sizes = [10, 15]\n",
    "rec_list_size = 20\n",
    "\n",
    "for f in nbhd_sizes:\n",
    "    print('Starting neighborhood size: ', f)\n",
    "    for p in range(len(pairs)): #partition_users(ml, 5, samp): #partition_rows(ml, 5): #partition_users(ml, 5, samp):\n",
    "        #print(len(train))\n",
    "        #print(len(test))\n",
    "        \n",
    "        train = pairs[p].train\n",
    "        test = pairs[p].test\n",
    "        \n",
    "        all_test.append(test)\n",
    "        print('Configuring algorithm...')\n",
    "        # configure the algorithm\n",
    "        algo = user_knn.UserUser(nnbrs = f) #als.BiasedMF(50)\n",
    "        # make sure it can recommend, not just predict\n",
    "        algo = Recommender.adapt(algo)\n",
    "        # train the algorithm\n",
    "        algo.fit(train)\n",
    "        print('Starting prediction process...')\n",
    "        # predict ratings\n",
    "        preds = batch.predict(algo, test, n_jobs = 2)\n",
    "        preds['nnbhrs'] = f\n",
    "        preds['RunId'] = p + 1\n",
    "        all_preds.append(preds)\n",
    "        print('Starting recommendation process...')\n",
    "        # produce recommendations\n",
    "        users = test['user'].unique()\n",
    "        recs = batch.recommend(algo, users, rec_list_size)\n",
    "        recs['nnbhrs'] = f ####\n",
    "        recs['RunId'] = p + 1\n",
    "        all_recs.append(recs)\n",
    "        print('Finishing neighborhood size: ', f)\n",
    "\n",
    "# integrate test data; since splits are disjoint users\n",
    "# for a single data set, this is sufficient\n",
    "recs = pd.concat(all_recs, ignore_index=True)\n",
    "preds = pd.concat(all_preds, ignore_index=True)\n",
    "test = pd.concat(all_test, ignore_index=True)\n",
    "# compute RMSE\n",
    "#print('RMSE:', rmse(preds['prediction'],preds['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>nnbhrs</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107559</td>\n",
       "      <td>5.065356</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106441</td>\n",
       "      <td>5.044886</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73290</td>\n",
       "      <td>4.854950</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3216</td>\n",
       "      <td>4.820168</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4754</td>\n",
       "      <td>4.820168</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     item     score  user  rank  nnbhrs  RunId\n",
       "0  107559  5.065356     1     1      10      1\n",
       "1  106441  5.044886     1     2      10      1\n",
       "2   73290  4.854950     1     3      10      1\n",
       "3    3216  4.820168     1     4      10      1\n",
       "4    4754  4.820168     1     5      10      1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs.head() # RECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prediction</th>\n",
       "      <th>nnbhrs</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "      <td>2.954023</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "      <td>1.573504</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "      <td>2.660112</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "      <td>2.949838</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "      <td>2.733989</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   timestamp  prediction  nnbhrs  RunId\n",
       "0     1  1263     2.0  1260759151    2.954023      10      1\n",
       "1     1  1371     2.5  1260759135    1.573504      10      1\n",
       "2     1  1287     2.0  1260759187    2.660112      10      1\n",
       "3     1  1953     4.0  1260759191    2.949838      10      1\n",
       "4     1  2105     4.0  1260759139    2.733989      10      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1263</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1260759135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1260759187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1953</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1260759139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating   timestamp\n",
       "0     1  1263     2.0  1260759151\n",
       "1     1  1371     2.5  1260759135\n",
       "2     1  1287     2.0  1260759187\n",
       "3     1  1953     4.0  1260759191\n",
       "4     1  2105     4.0  1260759139"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head() # TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.topn analyzing 26840 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 26840 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 26840 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-650623a572fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndcg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, recs, truth, include_missing)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'collecting metric results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'measured %d lists in %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, n_jobs)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0minvoker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rla_worker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_rla_worker\u001b[1;34m(model, req)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rla_worker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_compute_group\u001b[1;34m(self, col, val)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mmnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_measurements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_key\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_measurements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_records\u001b[1;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[0;32m   1594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1596\u001b[1;33m                 \u001b[0mfirst_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1597\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_iter_measurements\u001b[1;34m(self, col, val)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mg_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mg_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\metrics\\topn.py\u001b[0m in \u001b[0;36mndcg\u001b[1;34m(recs, truth, discount)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \"\"\"\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mtpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[0mtgood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpos\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'rating'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2733\u001b[1;33m             raise InvalidIndexError(\n\u001b[0m\u001b[0;32m   2734\u001b[0m                 \u001b[1;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2735\u001b[0m             )\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# compute nDCG for each user\n",
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "rla.add_metric(topn.precision)\n",
    "metrics = rla.compute(recs, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.topn analyzing 13420 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 13420 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn analyzing 13420 recommendations (6710 truth rows)\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using rec key columns ['nnbhrs', 'RunId', 'user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n",
      "[   INFO] lenskit.util.parallel setting up in-process worker\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7c35f8fa2ce8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnbhd_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mrec_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nnbhrs'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mmetrics_f\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrec_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics_f\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, recs, truth, include_missing)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mtimer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStopwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'collecting metric results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'measured %d lists in %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36mcompute\u001b[1;34m(self, n_jobs)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0minvoker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rla_worker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mobjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_rla_worker\u001b[1;34m(model, req)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rla_worker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_compute_group\u001b[1;34m(self, col, val)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mmnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mgen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_measurements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_key\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_measurements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mfrom_records\u001b[1;34m(cls, data, index, exclude, columns, coerce_float, nrows)\u001b[0m\n\u001b[0;32m   1594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1596\u001b[1;33m                 \u001b[0mfirst_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1597\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m_iter_measurements\u001b[1;34m(self, col, val)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mg_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\topn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mtk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrk\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mg_truth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg_truth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\lenskit_confidence\\lenskit\\metrics\\topn.py\u001b[0m in \u001b[0;36mndcg\u001b[1;34m(recs, truth, discount)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \"\"\"\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     \u001b[0mtpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[0mtgood\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtpos\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'rating'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   2731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2733\u001b[1;33m             raise InvalidIndexError(\n\u001b[0m\u001b[0;32m   2734\u001b[0m                 \u001b[1;34m\"Reindexing only valid with uniquely valued Index objects\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2735\u001b[0m             )\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# compute nDCG for each user\n",
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg)\n",
    "rla.add_metric(topn.precision)\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for f in nbhd_sizes:\n",
    "    rec_f = recs[recs['nnbhrs'] == f]\n",
    "    metrics_f = rla.compute(rec_f, test)\n",
    "    metrics.append(metrics_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and compute overall system performance\n",
    "print('NDCG:', metrics.groupby('nnbhrs')['ndcg'].mean())\n",
    "print('Precision:', metrics.groupby('nnbhrs')['precision'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "ndcg = raw_ndcg.join(runs[['AlgoClass', 'nnbrs']], on = 'RunId')\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lenskit import batch, topn, datasets\n",
    "from lenskit.algorithms.bias import Bias\n",
    "from lenskit.metrics.predict import rmse\n",
    "#from lenskit import datasets\n",
    "\n",
    "ml = datasets.MovieLens('../data/ml-latest-small').ratings\n",
    "\n",
    "ratings = ml\n",
    "bias = Bias()\n",
    "bias.fit(ratings[:-1000])\n",
    "\n",
    "preds = batch.predict(bias, ratings[-1000:])\n",
    "print(rmse(preds['prediction'], preds['rating']))\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['err'] = (preds['prediction'] - preds['rating'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress bars are useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes a little while to run things, and can get kinda quiet in here. Let's set up logging so we can see the logging output in the notebook's message stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.log_to_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then set up the data access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlsmall = MovieLens('../data/ml-latest-small')\n",
    "#mlsmall = MovieLens('../data/ml-1m')\n",
    "#mlsmall = MovieLens('../data/ml-10m')\n",
    "#mlsmall = MovieLens('../data/ml-20m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to run our evaluation and store its output in the `my-eval` directory, generating 20-item recommendation lists::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = MultiEval('my-eval', recommend = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use a 5-fold cross-validation setup.  We save the data into a list in memory so we have access to the test data later.  In a larger experiment, you might write the partitions to disk and pass the file names to `add_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(partition_users(mlsmall.ratings, 5, SampleN(5)))\n",
    "eval.add_datasets(pairs, name = 'ML-Small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([item_knn.ItemItem(nnbrs = f) for f in [10, 25, 50, 100]], \n",
    "                    attrs = ['nnbrs'], name = 'ItemKNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([user_knn.UserUser(nnbrs = f) for f in [10, 25, 50, 100]], \n",
    "                    attrs = ['nnbrs'], name = 'UserKNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add a popular baseline for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms(basic.Popular(), name = 'Pop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we will run the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.run(progress = tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.algorithms.bias import Bias\n",
    "from lenskit.metrics.predict import rmse\n",
    "from lenskit import datasets\n",
    "ratings = mlsmall.ratings #datasets.MovieLens('data/ml-latest-small').ratings\n",
    "bias = Bias()\n",
    "bias.fit(ratings)\n",
    "#<lenskit.algorithms.bias.Bias object at ...>\n",
    "preds = predict(bias, ratings)\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Now that the experiment is run, we can read its outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(eval, mlsmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace = True)\n",
    "runs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes each run - a data set, partition, and algorithm combination.  To evaluate, we need to get the actual recommendations, and combine them with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compute per-(run,user) evaluations of the recommendations *before* combining with metadata. \n",
    "\n",
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg) # precision, recall, recip_rank, dcg, ndcg\n",
    "rla.add_metric(topn.precision)\n",
    "#rla.add_metric(predict.rmse)\n",
    "raw_ndcg = rla.compute(recs, truth)\n",
    "raw_ndcg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "ndcg = raw_ndcg.join(runs[['AlgoClass', 'nnbrs']], on = 'RunId')\n",
    "ndcg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the overall average performance for each algorithm configuration - fillna makes the group-by happy with Popular's lack of a feature count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "ndcg.fillna(0).groupby(['AlgoClass', 'nnbrs'])['ndcg','precision'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "mf_scores = ndcg.groupby(['AlgoClass', 'nnbrs'])['ndcg'].mean().reset_index()\n",
    "#pop_score = ndcg[ndcg['AlgoClass'] == 'Popular']['ndcg'].mean()\n",
    "#plt.axhline(pop_score, color='grey', linestyle='--', label='Popular')\n",
    "for algo, data in mf_scores.groupby('AlgoClass'):\n",
    "    plt.plot(data['nnbrs'], data['ndcg'], label=algo)\n",
    "plt.legend()\n",
    "plt.xlabel('nnbrs')\n",
    "plt.ylabel('nDCG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR NEIGHBORHOOD-BASED METHODS ONLY ###\n",
    "mf_scores = ndcg.groupby(['AlgoClass', 'nnbrs'])['precision'].mean().reset_index()\n",
    "#pop_score = ndcg[ndcg['AlgoClass'] == 'Popular']['ndcg'].mean()\n",
    "#plt.axhline(pop_score, color='grey', linestyle='--', label='Popular')\n",
    "for algo, data in mf_scores.groupby('AlgoClass'):\n",
    "    plt.plot(data['nnbrs'], data['precision'], label=algo)\n",
    "plt.legend()\n",
    "plt.xlabel('nnbrs')\n",
    "plt.ylabel('Precision')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
