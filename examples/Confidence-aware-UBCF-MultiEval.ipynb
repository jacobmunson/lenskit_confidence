{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence-aware UBCF MultiEval Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much is this structure and organization is borrowed from the Lenskit sample evaluation walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # set path of locally install lenskit_confidence module\n",
    "sys.path.insert(0,'C:\\\\Users\\\\Name\\\\Documents\\\\GitHub\\\\lenskit_confidence') # Looks like this on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.metrics import predict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lenskit.batch_ca import MultiEval\n",
    "from lenskit.algorithms_ca import user_knn_ca, Recommender # *not* user_knn\n",
    "from lenskit import topn, datasets, batch_ca # *not* batch \n",
    "from lenskit import datasets\n",
    "from lenskit.datasets import MovieLens\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit import topn, util #, metrics\n",
    "from lenskit.crossfold import partition_users, SampleN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a progress bar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup logging to the notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.log notebook logging configured\n"
     ]
    }
   ],
   "source": [
    "util.log_to_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a dataset to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MovieLens('../data/ml-1m')\n",
    "#data = MovieLens('../data/ml-10m')\n",
    "#data = MovieLens('../data/ml-20m')\n",
    "#data = MovieLens('../data/jester') # with Jester cleaning, it's the same format a ML datasets, so the ML input function works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment and store output in the `my-eval` directory. \n",
    "\n",
    "We're not producing prediction, generating 10-item recommendation lists, and setting up 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = MultiEval('my-eval', predict = False, recommend = 10, eval_n_jobs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 5-fold CV, partitioning users and putting 5 ratings per user in the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.crossfold partitioning 1000209 rows for 6040 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n"
     ]
    }
   ],
   "source": [
    "pairs = list(partition_users(data.ratings, 5, SampleN(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the dataset to MultiEval with `add_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_datasets(pairs, name = 'ML1M') # give the added dataset a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhbr_range = [25] # We'll use just K=25 for our sample evaluation [10, 25, 50, 75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the algorithms to MultiEval with `add_algorithms`; the three CUBCF options are listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([user_knn_ca.UserUserCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'UserKNN-CA-Average') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([user_knn_ca.UserUserCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-jackknife-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'UserKNN-CA-JK-Average') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([user_knn_ca.UserUserCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-bootstrap-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'UserKNN-CA-BS-Average') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393749d212d248308c358b970bea1535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch_ca._multi_ca starting run 1: UserUserCA(nnbrs=25, min_sim=0) on ML1M:1\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting UserUserCA(nnbrs=25, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm UserUserCA(nnbrs=25, min_sim=0) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.user_knn_ca calling fit in user_knn\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm UserUserCA(nnbrs=25, min_sim=0) in 6.24s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/UserUserCA(nnbrs=25, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUserCA(nnbrs=25, min_sim=0) to 1176 pickle bytes with 13 buffers of 28104104 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/UserUserCA(nnbrs=25, min_sim=0) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 39.75s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 40.69s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 1: UserUserCA(nnbrs=25, min_sim=0) on ML1M:1\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 2: UserUserCA(nnbrs=25, min_sim=0) on ML1M:2\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting UserUserCA(nnbrs=25, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm UserUserCA(nnbrs=25, min_sim=0) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.user_knn_ca calling fit in user_knn\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm UserUserCA(nnbrs=25, min_sim=0) in  477ms\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/UserUserCA(nnbrs=25, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUserCA(nnbrs=25, min_sim=0) to 1176 pickle bytes with 13 buffers of 28104124 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/UserUserCA(nnbrs=25, min_sim=0) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 39.80s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 40.62s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 2: UserUserCA(nnbrs=25, min_sim=0) on ML1M:2\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 3: UserUserCA(nnbrs=25, min_sim=0) on ML1M:3\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting UserUserCA(nnbrs=25, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm UserUserCA(nnbrs=25, min_sim=0) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.user_knn_ca calling fit in user_knn\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm UserUserCA(nnbrs=25, min_sim=0) in  471ms\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/UserUserCA(nnbrs=25, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUserCA(nnbrs=25, min_sim=0) to 1176 pickle bytes with 13 buffers of 28104144 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/UserUserCA(nnbrs=25, min_sim=0) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 39.70s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 40.53s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 3: UserUserCA(nnbrs=25, min_sim=0) on ML1M:3\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 4: UserUserCA(nnbrs=25, min_sim=0) on ML1M:4\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting UserUserCA(nnbrs=25, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm UserUserCA(nnbrs=25, min_sim=0) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.user_knn_ca calling fit in user_knn\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm UserUserCA(nnbrs=25, min_sim=0) in  473ms\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/UserUserCA(nnbrs=25, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUserCA(nnbrs=25, min_sim=0) to 1176 pickle bytes with 13 buffers of 28104104 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/UserUserCA(nnbrs=25, min_sim=0) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 39.30s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 40.11s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 4: UserUserCA(nnbrs=25, min_sim=0) on ML1M:4\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 5: UserUserCA(nnbrs=25, min_sim=0) on ML1M:5\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting UserUserCA(nnbrs=25, min_sim=0) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm UserUserCA(nnbrs=25, min_sim=0) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.user_knn_ca calling fit in user_knn\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm UserUserCA(nnbrs=25, min_sim=0) in  465ms\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/UserUserCA(nnbrs=25, min_sim=0)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/UserUserCA(nnbrs=25, min_sim=0) to 1176 pickle bytes with 13 buffers of 28104144 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/UserUserCA(nnbrs=25, min_sim=0) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 42.14s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 42.94s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 5: UserUserCA(nnbrs=25, min_sim=0) on ML1M:5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval.run(progress = tqdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results\n",
    "\n",
    "We need to read in experiment outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Partition</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>AlgoStr</th>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "      <th>TrainTime</th>\n",
       "      <th>PredTime</th>\n",
       "      <th>RecTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>1</td>\n",
       "      <td>UserUserCA</td>\n",
       "      <td>UserUserCA(nnbrs=25, min_sim=0)</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>6.239759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.693732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>2</td>\n",
       "      <td>UserUserCA</td>\n",
       "      <td>UserUserCA(nnbrs=25, min_sim=0)</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>0.477325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.619449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>3</td>\n",
       "      <td>UserUserCA</td>\n",
       "      <td>UserUserCA(nnbrs=25, min_sim=0)</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>0.471221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.531695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>4</td>\n",
       "      <td>UserUserCA</td>\n",
       "      <td>UserUserCA(nnbrs=25, min_sim=0)</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>0.472944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.113802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>5</td>\n",
       "      <td>UserUserCA</td>\n",
       "      <td>UserUserCA(nnbrs=25, min_sim=0)</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>0.465477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.940498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DataSet  Partition   AlgoClass                          AlgoStr  \\\n",
       "RunId                                                                   \n",
       "1        ML1M          1  UserUserCA  UserUserCA(nnbrs=25, min_sim=0)   \n",
       "2        ML1M          2  UserUserCA  UserUserCA(nnbrs=25, min_sim=0)   \n",
       "3        ML1M          3  UserUserCA  UserUserCA(nnbrs=25, min_sim=0)   \n",
       "4        ML1M          4  UserUserCA  UserUserCA(nnbrs=25, min_sim=0)   \n",
       "5        ML1M          5  UserUserCA  UserUserCA(nnbrs=25, min_sim=0)   \n",
       "\n",
       "                     name  nnbrs  TrainTime  PredTime    RecTime  \n",
       "RunId                                                             \n",
       "1      UserKNN-CA-Average     25   6.239759       NaN  40.693732  \n",
       "2      UserKNN-CA-Average     25   0.477325       NaN  40.619449  \n",
       "3      UserKNN-CA-Average     25   0.471221       NaN  40.531695  \n",
       "4      UserKNN-CA-Average     25   0.472944       NaN  40.113802  \n",
       "5      UserKNN-CA-Average     25   0.465477       NaN  42.940498  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace = True)\n",
    "runs.head() # a quick visual check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes each run - a data set, partition, and algorithm combination.  To evaluate, we need to get the actual recommendations, and combine them with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>prediction</th>\n",
       "      <th>user</th>\n",
       "      <th>var</th>\n",
       "      <th>num_nbhr</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420</td>\n",
       "      <td>4.087044</td>\n",
       "      <td>1</td>\n",
       "      <td>0.245267</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2503</td>\n",
       "      <td>2.259555</td>\n",
       "      <td>1</td>\n",
       "      <td>0.352640</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2197</td>\n",
       "      <td>2.256934</td>\n",
       "      <td>1</td>\n",
       "      <td>0.320579</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3245</td>\n",
       "      <td>1.948881</td>\n",
       "      <td>1</td>\n",
       "      <td>0.480832</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3293</td>\n",
       "      <td>1.452391</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518395</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  prediction  user       var  num_nbhr  rank  RunId\n",
       "0  1420    4.087044     1  0.245267       3.0     1      1\n",
       "1  2503    2.259555     1  0.352640       5.0     2      1\n",
       "2  2197    2.256934     1  0.320579       6.0     3      1\n",
       "3  3245    1.948881     1  0.480832       3.0     4      1\n",
       "4  3293    1.452391     1  0.518395       2.0     5      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs['score'] = recs['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1420</td>\n",
       "      <td>4.087044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2503</td>\n",
       "      <td>2.259555</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2197</td>\n",
       "      <td>2.256934</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3245</td>\n",
       "      <td>1.948881</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3293</td>\n",
       "      <td>1.452391</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item     score  user  rank  RunId\n",
       "0  1420  4.087044     1     1      1\n",
       "1  2503  2.259555     1     2      1\n",
       "2  2197  2.256934     1     3      1\n",
       "3  3245  1.948881     1     4      1\n",
       "4  3293  1.452391     1     5      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = recs[['item', 'score', 'user','rank','RunId']]\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the predictions... (this is here for posterity, we're not actually making predictions on test set now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preds = pd.read_parquet('my-eval/predictions.parquet')\n",
    "#preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compute per-(run,user) evaluations of the recommendations *before* combining with metadata. \n",
    "\n",
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2791</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978302188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978301953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978300055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1907</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978824330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "      <td>978301777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user  item  rating  timestamp\n",
       "0          16     1  2791     4.0  978302188\n",
       "1          27     1  1097     4.0  978301953\n",
       "2          23     1  1270     5.0  978300055\n",
       "3          35     1  1907     4.0  978824330\n",
       "4          46     1  1028     5.0  978301777"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index = True)\n",
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.to_csv('my-eval/truth.csv') # saving truth values to a csv for future evaluation\n",
    "#truth = pd.read_csv('my-eval/truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = truth[['user', 'item', 'rating']] # just grabbing what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2791</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1270</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1907</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1028</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     1  2791     4.0\n",
       "1     1  1097     4.0\n",
       "2     1  1270     5.0\n",
       "3     1  1907     4.0\n",
       "4     1  1028     5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head() # a visual check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.topn analyzing 60400 recommendations (30200 truth rows)\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x000001BC1EAEF1C0> to 1474960 pickle bytes with 12083 buffers of 2416000 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.topn measured 6040 lists in 19.53s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg  precision\n",
       "RunId user                        \n",
       "1     1      10.0   0.0        0.0\n",
       "      3      10.0   0.0        0.0\n",
       "      4      10.0   0.0        0.0\n",
       "      8      10.0   0.0        0.0\n",
       "      22     10.0   0.0        0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg) # precision, recall, recip_rank, dcg, ndcg\n",
    "rla.add_metric(topn.precision)\n",
    "topn_compute = rla.compute(recs, truth)\n",
    "topn_compute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UserKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg  precision                name  nnbrs\n",
       "RunId user                                                   \n",
       "1     1      10.0   0.0        0.0  UserKNN-CA-Average     25\n",
       "      3      10.0   0.0        0.0  UserKNN-CA-Average     25\n",
       "      4      10.0   0.0        0.0  UserKNN-CA-Average     25\n",
       "      8      10.0   0.0        0.0  UserKNN-CA-Average     25\n",
       "      22     10.0   0.0        0.0  UserKNN-CA-Average     25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_results = topn_compute.join(runs[['name', 'nnbrs']], on = 'RunId') # \n",
    "topn_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the overall average performance for each algorithm configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-a4fd14d57be5>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  topn_results.fillna(0).groupby(['name', 'nnbrs'])['ndcg','precision'].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UserKNN-CA-Average</th>\n",
       "      <th>25</th>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.005596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ndcg  precision\n",
       "name               nnbrs                     \n",
       "UserKNN-CA-Average 25     0.007986   0.005596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_results.fillna(0).groupby(['name', 'nnbrs'])['ndcg','precision'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
