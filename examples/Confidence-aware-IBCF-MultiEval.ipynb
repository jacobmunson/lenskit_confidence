{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence-aware IBCF MultiEval Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much is this structure and organization is borrowed from the Lenskit sample evaluation walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # set path of locally install lenskit_confidence module\n",
    "sys.path.insert(0,'C:\\\\Users\\\\Name\\\\Documents\\\\GitHub\\\\lenskit_confidence') # Looks like this on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenskit.metrics import predict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lenskit.batch_ca import MultiEval\n",
    "from lenskit.algorithms_ca import item_knn_ca, Recommender # *not* user_knn\n",
    "from lenskit import topn, datasets, batch_ca # *not* batch \n",
    "from lenskit import datasets\n",
    "from lenskit.datasets import MovieLens\n",
    "from lenskit import crossfold as xf\n",
    "from lenskit import topn, util #, metrics\n",
    "from lenskit.crossfold import partition_users, SampleN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up a progress bar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\anaconda3\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup logging to the notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.util.log notebook logging configured\n"
     ]
    }
   ],
   "source": [
    "util.log_to_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a dataset to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MovieLens('../data/ml-1m')\n",
    "#data = MovieLens('../data/ml-10m')\n",
    "#data = MovieLens('../data/ml-20m')\n",
    "#data = MovieLens('../data/jester') # with Jester cleaning, it's the same format a ML datasets, so the ML input function works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment and store output in the `my-eval` directory. \n",
    "\n",
    "We're not producing prediction, generating 10-item recommendation lists, and setting up 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = MultiEval('my-eval', predict = False, recommend = 10, eval_n_jobs = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 5-fold CV, partitioning users and putting 5 ratings per user in the test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.crossfold partitioning 1000209 rows for 6040 users into 5 partitions\n",
      "[   INFO] lenskit.crossfold fold 0: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 0: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 1: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 1: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 2: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 2: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 3: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 3: partitioning training data\n",
      "[   INFO] lenskit.crossfold fold 4: selecting test ratings\n",
      "[   INFO] lenskit.crossfold fold 4: partitioning training data\n"
     ]
    }
   ],
   "source": [
    "pairs = list(partition_users(data.ratings, 5, SampleN(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the dataset to MultiEval with `add_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_datasets(pairs, name = 'ML1M') # give the added dataset a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhbr_range = [25] # We'll use just K=25 for our sample evaluation [10, 25, 50, 75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the algorithms to MultiEval with `add_algorithms`; the three CIBCF options are listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([item_knn_ca.ItemItemCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'ItemKNN-CA-Average') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([item_knn_ca.ItemItemCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-jackknife-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'ItemKNN-CA-JK-Average') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.add_algorithms([item_knn_ca.ItemItemCA(nnbrs = f, aggregate = 'average', \n",
    "                                            variance_estimator = 'standard-deviation-bootstrap-average') for f in nhbr_range], \n",
    "                    attrs = ['nnbrs'], name = 'ItemKNN-CA-BS-Average') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabb5620f6ca40c081c209ab90e57589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.batch_ca._multi_ca starting run 1: ItemItemCA(nnbrs=25, msize=None) on ML1M:1\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting ItemItemCA(nnbrs=25, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm ItemItemCA(nnbrs=25, msize=None) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [1.15s] made sparse matrix for 3706 items (994169 ratings from 6040 users)\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [1.24s] computed means for 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [1.36s] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [1.37s] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [3.84s] splitting 3706 items (992541 ratings) into 4 blocks\n",
      "[   INFO] numba.core.transforms finding looplift candidates\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [12.41s] computed 7917466 similarities for 3706 items in 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [12.52s] sorting similarity matrix with 7917466 entries\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [14.99s] got neighborhoods for 3559 of 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [14.99s] computed 7917466 neighbor pairs\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [15.80s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm ItemItemCA(nnbrs=25, msize=None) in 15.99s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/ItemItemCA(nnbrs=25, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItemCA(nnbrs=25, msize=None) to 1396 pickle bytes with 17 buffers of 206248760 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/ItemItemCA(nnbrs=25, msize=None) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 51.19s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 52.16s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 1: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 1: ItemItemCA(nnbrs=25, msize=None) on ML1M:1\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 2: ItemItemCA(nnbrs=25, msize=None) on ML1M:2\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting ItemItemCA(nnbrs=25, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm ItemItemCA(nnbrs=25, msize=None) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 194ms] made sparse matrix for 3706 items (994169 ratings from 6040 users)\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 295ms] computed means for 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 420ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 423ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 486ms] splitting 3706 items (993277 ratings) into 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.47s] computed 7915240 similarities for 3706 items in 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.57s] sorting similarity matrix with 7915240 entries\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.84s] got neighborhoods for 3559 of 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.84s] computed 7915240 neighbor pairs\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.28s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm ItemItemCA(nnbrs=25, msize=None) in 5.47s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/ItemItemCA(nnbrs=25, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItemCA(nnbrs=25, msize=None) to 1396 pickle bytes with 17 buffers of 206195336 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/ItemItemCA(nnbrs=25, msize=None) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 50.23s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 51.12s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 2: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 2: ItemItemCA(nnbrs=25, msize=None) on ML1M:2\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 3: ItemItemCA(nnbrs=25, msize=None) on ML1M:3\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting ItemItemCA(nnbrs=25, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm ItemItemCA(nnbrs=25, msize=None) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 207ms] made sparse matrix for 3704 items (994169 ratings from 6040 users)\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 301ms] computed means for 3704 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 417ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 420ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 479ms] splitting 3704 items (992816 ratings) into 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.42s] computed 7918506 similarities for 3704 items in 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.52s] sorting similarity matrix with 7918506 entries\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.81s] got neighborhoods for 3560 of 3704 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.81s] computed 7918506 neighbor pairs\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.26s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm ItemItemCA(nnbrs=25, msize=None) in 5.44s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/ItemItemCA(nnbrs=25, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItemCA(nnbrs=25, msize=None) to 1396 pickle bytes with 17 buffers of 206273624 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/ItemItemCA(nnbrs=25, msize=None) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 51.18s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 52.02s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 3: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 3: ItemItemCA(nnbrs=25, msize=None) on ML1M:3\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 4: ItemItemCA(nnbrs=25, msize=None) on ML1M:4\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting ItemItemCA(nnbrs=25, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm ItemItemCA(nnbrs=25, msize=None) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 209ms] made sparse matrix for 3706 items (994169 ratings from 6040 users)\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 323ms] computed means for 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 466ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 470ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 536ms] splitting 3706 items (992736 ratings) into 4 blocks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.48s] computed 7915512 similarities for 3706 items in 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.58s] sorting similarity matrix with 7915512 entries\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.84s] got neighborhoods for 3560 of 3706 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.85s] computed 7915512 neighbor pairs\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.33s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm ItemItemCA(nnbrs=25, msize=None) in 5.51s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/ItemItemCA(nnbrs=25, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItemCA(nnbrs=25, msize=None) to 1396 pickle bytes with 17 buffers of 206201864 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/ItemItemCA(nnbrs=25, msize=None) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 51.15s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 52.12s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 4: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 4: ItemItemCA(nnbrs=25, msize=None) on ML1M:4\n",
      "[   INFO] lenskit.batch_ca._multi_ca starting run 5: ItemItemCA(nnbrs=25, msize=None) on ML1M:5\n",
      "[   INFO] lenskit.batch_ca._multi_ca adapting ItemItemCA(nnbrs=25, msize=None) into a recommender\n",
      "[   INFO] lenskit.batch_ca._multi_ca training algorithm ItemItemCA(nnbrs=25, msize=None) on 994169 ratings\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 216ms] made sparse matrix for 3705 items (994169 ratings from 6040 users)\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 323ms] computed means for 3705 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 448ms] normalized rating matrix columns\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 453ms] computing similarity matrix\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [ 522ms] splitting 3705 items (993317 ratings) into 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.72s] computed 7918764 similarities for 3705 items in 4 blocks\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [4.82s] sorting similarity matrix with 7918764 entries\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.08s] got neighborhoods for 3559 of 3705 items\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.08s] computed 7918764 neighbor pairs\n",
      "[   INFO] lenskit.algorithms_ca.item_knn_ca [5.53s] transposed matrix for optimization\n",
      "[   INFO] lenskit.algorithms_ca.basic_ca trained unrated candidate selector for 994169 ratings\n",
      "[   INFO] lenskit.batch_ca._multi_ca trained algorithm ItemItemCA(nnbrs=25, msize=None) in 5.71s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generating recommendations for 1208 users for TopN/ItemItemCA(nnbrs=25, msize=None)\n",
      "[   INFO] lenskit.sharing.shm serialized TopN/ItemItemCA(nnbrs=25, msize=None) to 1396 pickle bytes with 17 buffers of 206279864 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 4 workers\n",
      "[   INFO] lenskit.batch_ca._recommend_ca  (2) recommending with TopN/ItemItemCA(nnbrs=25, msize=None) for 1208 users (n_jobs=4)\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] numexpr.utils NumExpr defaulting to 4 threads.\n",
      "[   INFO] lenskit.batch_ca._recommend_ca recommended for 1208 users in 51.62s\n",
      "[   INFO] lenskit.batch_ca._multi_ca generated recommendations in 52.57s\n",
      "[   INFO] lenskit.batch_ca._multi_ca run 5: writing results to my-eval\\recommendations.parquet\n",
      "[   INFO] lenskit.batch_ca._multi_ca finished run 5: ItemItemCA(nnbrs=25, msize=None) on ML1M:5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval.run(progress = tqdm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results\n",
    "\n",
    "We need to read in experiment outputs.\n",
    "\n",
    "First the run metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>Partition</th>\n",
       "      <th>AlgoClass</th>\n",
       "      <th>AlgoStr</th>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "      <th>TrainTime</th>\n",
       "      <th>PredTime</th>\n",
       "      <th>RecTime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>1</td>\n",
       "      <td>ItemItemCA</td>\n",
       "      <td>ItemItemCA(nnbrs=25, msize=None)</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>15.991513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.159636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>2</td>\n",
       "      <td>ItemItemCA</td>\n",
       "      <td>ItemItemCA(nnbrs=25, msize=None)</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>5.469378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.119131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>3</td>\n",
       "      <td>ItemItemCA</td>\n",
       "      <td>ItemItemCA(nnbrs=25, msize=None)</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>5.441524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.023368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>4</td>\n",
       "      <td>ItemItemCA</td>\n",
       "      <td>ItemItemCA(nnbrs=25, msize=None)</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>5.512648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.118117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ML1M</td>\n",
       "      <td>5</td>\n",
       "      <td>ItemItemCA</td>\n",
       "      <td>ItemItemCA(nnbrs=25, msize=None)</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "      <td>5.705166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.571828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DataSet  Partition   AlgoClass                           AlgoStr  \\\n",
       "RunId                                                                    \n",
       "1        ML1M          1  ItemItemCA  ItemItemCA(nnbrs=25, msize=None)   \n",
       "2        ML1M          2  ItemItemCA  ItemItemCA(nnbrs=25, msize=None)   \n",
       "3        ML1M          3  ItemItemCA  ItemItemCA(nnbrs=25, msize=None)   \n",
       "4        ML1M          4  ItemItemCA  ItemItemCA(nnbrs=25, msize=None)   \n",
       "5        ML1M          5  ItemItemCA  ItemItemCA(nnbrs=25, msize=None)   \n",
       "\n",
       "                     name  nnbrs  TrainTime  PredTime    RecTime  \n",
       "RunId                                                             \n",
       "1      ItemKNN-CA-Average     25  15.991513       NaN  52.159636  \n",
       "2      ItemKNN-CA-Average     25   5.469378       NaN  51.119131  \n",
       "3      ItemKNN-CA-Average     25   5.441524       NaN  52.023368  \n",
       "4      ItemKNN-CA-Average     25   5.512648       NaN  52.118117  \n",
       "5      ItemKNN-CA-Average     25   5.705166       NaN  52.571828  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = pd.read_csv('my-eval/runs.csv')\n",
    "runs.set_index('RunId', inplace = True)\n",
    "runs.head() # a quick visual check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes each run - a data set, partition, and algorithm combination.  To evaluate, we need to get the actual recommendations, and combine them with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>prediction</th>\n",
       "      <th>user</th>\n",
       "      <th>var</th>\n",
       "      <th>num_nbhr</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0.633304</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731744</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2839</td>\n",
       "      <td>0.556983</td>\n",
       "      <td>3</td>\n",
       "      <td>0.658207</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503</td>\n",
       "      <td>0.543428</td>\n",
       "      <td>3</td>\n",
       "      <td>0.856513</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>904</td>\n",
       "      <td>0.444571</td>\n",
       "      <td>3</td>\n",
       "      <td>1.057868</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3517</td>\n",
       "      <td>0.421464</td>\n",
       "      <td>3</td>\n",
       "      <td>0.757622</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  prediction  user       var  num_nbhr  rank  RunId\n",
       "0    53    0.633304     3  0.731744        25     1      1\n",
       "1  2839    0.556983     3  0.658207        25     2      1\n",
       "2  2503    0.543428     3  0.856513        25     3      1\n",
       "3   904    0.444571     3  1.057868        25     4      1\n",
       "4  3517    0.421464     3  0.757622        25     5      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = pd.read_parquet('my-eval/recommendations.parquet')\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs['score'] = recs['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>score</th>\n",
       "      <th>user</th>\n",
       "      <th>rank</th>\n",
       "      <th>RunId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>0.633304</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2839</td>\n",
       "      <td>0.556983</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2503</td>\n",
       "      <td>0.543428</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>904</td>\n",
       "      <td>0.444571</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3517</td>\n",
       "      <td>0.421464</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item     score  user  rank  RunId\n",
       "0    53  0.633304     3     1      1\n",
       "1  2839  0.556983     3     2      1\n",
       "2  2503  0.543428     3     3      1\n",
       "3   904  0.444571     3     4      1\n",
       "4  3517  0.421464     3     5      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = recs[['item', 'score', 'user','rank','RunId']]\n",
    "recs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the predictions... (this is here for posterity, we're not actually making predictions on test set now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#preds = pd.read_parquet('my-eval/predictions.parquet')\n",
    "#preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compute per-(run,user) evaluations of the recommendations *before* combining with metadata. \n",
    "\n",
    "In order to evaluate the recommendation list, we need to build a combined set of truth data. Since this is a disjoint partition of users over a single data set, we can just concatenate the individual test frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>3</td>\n",
       "      <td>1394</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978298147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>3</td>\n",
       "      <td>1196</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978297539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>229</td>\n",
       "      <td>3</td>\n",
       "      <td>2871</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978297539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>213</td>\n",
       "      <td>3</td>\n",
       "      <td>590</td>\n",
       "      <td>4.0</td>\n",
       "      <td>978297439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184</td>\n",
       "      <td>3</td>\n",
       "      <td>1641</td>\n",
       "      <td>2.0</td>\n",
       "      <td>978298430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user  item  rating  timestamp\n",
       "0         186     3  1394     4.0  978298147\n",
       "1         212     3  1196     4.0  978297539\n",
       "2         229     3  2871     4.0  978297539\n",
       "3         213     3   590     4.0  978297439\n",
       "4         184     3  1641     2.0  978298430"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = pd.concat((p.test for p in pairs), ignore_index = True)\n",
    "truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth.to_csv('my-eval/truth.csv') # saving truth values to a csv for future evaluation\n",
    "# truth = pd.read_csv('my-eval/truth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = truth[['user', 'item', 'rating']] # just grabbing what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1394</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1196</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2871</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>590</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     3  1394     4.0\n",
       "1     3  1196     4.0\n",
       "2     3  2871     4.0\n",
       "3     3   590     4.0\n",
       "4     3  1641     2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.head() # a visual check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up an analysis and compute the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   INFO] lenskit.topn analyzing 60400 recommendations (30200 truth rows)\n",
      "[   INFO] lenskit.topn using rec key columns ['RunId', 'user']\n",
      "[   INFO] lenskit.topn using truth key columns ['user']\n",
      "[   INFO] lenskit.topn collecting truth data\n",
      "[   INFO] lenskit.topn collecting metric results\n",
      "[   INFO] lenskit.sharing.shm serialized <lenskit.topn._RLAJob object at 0x0000024EE768B400> to 1474960 pickle bytes with 12083 buffers of 2416000 bytes\n",
      "[   INFO] lenskit.util.parallel setting up ProcessPoolExecutor w/ 2 workers\n",
      "[   INFO] lenskit.topn measured 6040 lists in 22.52s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg  precision\n",
       "RunId user                        \n",
       "1     3      10.0   0.0        0.0\n",
       "      4      10.0   0.0        0.0\n",
       "      5      10.0   0.0        0.0\n",
       "      11     10.0   0.0        0.0\n",
       "      12     10.0   0.0        0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rla = topn.RecListAnalysis()\n",
    "rla.add_metric(topn.ndcg) # precision, recall, recip_rank, dcg, ndcg\n",
    "rla.add_metric(topn.precision)\n",
    "topn_compute = rla.compute(recs, truth)\n",
    "topn_compute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to combine this with our run data, so that we know what algorithms and configurations we are evaluating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>nrecs</th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RunId</th>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ItemKNN-CA-Average</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nrecs  ndcg  precision                name  nnbrs\n",
       "RunId user                                                   \n",
       "1     3      10.0   0.0        0.0  ItemKNN-CA-Average     25\n",
       "      4      10.0   0.0        0.0  ItemKNN-CA-Average     25\n",
       "      5      10.0   0.0        0.0  ItemKNN-CA-Average     25\n",
       "      11     10.0   0.0        0.0  ItemKNN-CA-Average     25\n",
       "      12     10.0   0.0        0.0  ItemKNN-CA-Average     25"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_results = topn_compute.join(runs[['name', 'nnbrs']], on = 'RunId') # \n",
    "topn_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the overall average performance for each algorithm configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-a4fd14d57be5>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  topn_results.fillna(0).groupby(['name', 'nnbrs'])['ndcg','precision'].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ndcg</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th>nnbrs</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemKNN-CA-Average</th>\n",
       "      <th>25</th>\n",
       "      <td>0.007913</td>\n",
       "      <td>0.005563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ndcg  precision\n",
       "name               nnbrs                     \n",
       "ItemKNN-CA-Average 25     0.007913   0.005563"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topn_results.fillna(0).groupby(['name', 'nnbrs'])['ndcg','precision'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
